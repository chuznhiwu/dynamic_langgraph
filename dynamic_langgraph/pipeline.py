# dynamic_langgraph/pipeline.py
import logging
import json
import asyncio
import os
import re, time  # æ–°å¢
import uuid
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .case_loader import load_case_templates, llm_pick_tasks
from .graph_builder import build_graph
from .utils import split_thought_and_answer

from scripts.recorder import record_step
from minio_client import upload_file_to_minio  # ä½ çš„å°è£…ï¼šå¯è¿”å›ç›´é“¾/é¢„ç­¾å/None

# ---------------- ç¯å¢ƒ & æœ¬åœ°ç›®å½• ----------------
MINIO_BUCKET = os.getenv("MINIO_BUCKET", "dynamic-langgraph")
MINIO_BASE_URL = os.getenv("MINIO_BASE_URL", "").rstrip("/")

# è‹¥ minio_client é‡Œä¹Ÿå®šä¹‰äº†å¸¸é‡ï¼Œä¼˜å…ˆä½¿ç”¨
try:
    from minio_client import MINIO_BUCKET as _MB  # type: ignore
    if _MB:
        MINIO_BUCKET = _MB
except Exception:
    pass
try:
    from minio_client import MINIO_BASE_URL as _MBU  # type: ignore
    if _MBU:
        MINIO_BASE_URL = _MBU.rstrip("/")
except Exception:
    pass

_LOG_DIR = (Path(__file__).resolve().parent.parent / "log")
_LOG_DIR.mkdir(exist_ok=True)
_GRAPHS_DIR = (Path(__file__).resolve().parent.parent / "graphs")
_GRAPHS_DIR.mkdir(exist_ok=True)

logger = logging.getLogger("dynamic-langgraph.pipeline")
logging.basicConfig(level=logging.INFO)

# ================== å°å·¥å…· ==================
def safe_serialize(obj: Any) -> Any:
    if isinstance(obj, Path):
        return str(obj)
    if isinstance(obj, dict):
        return {k: safe_serialize(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [safe_serialize(v) for v in obj]
    return obj

def _mk_key(prefix: str, session_id: str, name: str) -> str:
    """
    ç”Ÿæˆå¯¹è±¡é”®ï¼š<prefix>/<session_id>/<ts>_<uuid8>_<name>
    ä¾‹ï¼špic/abcd.../1723530001_a1b2c3d4_chart.png
    """
    ts = int(time.time())
    uid = uuid.uuid4().hex[:8]
    safe_name = name.replace(" ", "_")
    return f"{prefix.strip('/')}/{session_id}/{ts}_{uid}_{safe_name}"

def _compose_url(object_key: str) -> str:
    """
    è¿”å›ä¸€ä¸ªå¯è®¿é—® URLï¼ˆä¼˜å…ˆ MINIO_BASE_URLï¼Œé€€åŒ–æ—¶è¿”å› /bucket/objectï¼‰ã€‚
    """
    if MINIO_BASE_URL:
        return f"{MINIO_BASE_URL}/{MINIO_BUCKET}/{object_key}"
    return f"/{MINIO_BUCKET}/{object_key}"

def _upload_and_get_url(local_path: str, object_key: str) -> str:
    """
    ä¸Šä¼ å¹¶å°½åŠ›å¾—åˆ° URLï¼š
    - upload_file_to_minio è¿”å› URL/è·¯å¾„åˆ™ä¼˜å…ˆç”¨ï¼›
    - å¦åˆ™ç”¨ _compose_url(object_key) æ‹¼ã€‚
    """
    ret = upload_file_to_minio(local_path, object_key)
    if isinstance(ret, str) and (ret.startswith("http://") or ret.startswith("https://") or ret.startswith("/")):
        return ret
    return _compose_url(object_key)


def sid_core(session_id: str) -> str:
    """å»æ‰å‰ç¼€ 'owui-'ï¼Œå¾—åˆ° b9d605d2002b4fb0975804ab è¿™ç§æ ¸å¿ƒID"""
    return re.sub(r"^owui-", "", session_id or "")


async def emit_image_from_file(session_id: str, local_path: str, *, prefix: str = "pic") -> str:
    """
    ä¸Šä¼ ä¸€å¼ å›¾ç‰‡å¹¶æ¨é€äº‹ä»¶ï¼ˆå‰ç«¯ä¼šå†…åµŒæ˜¾ç¤ºï¼‰ï¼š
    - äº‹ä»¶ï¼štype="image"ï¼Œcontent=<url>
    """
    name = Path(local_path).name
    object_key = _mk_key(prefix, session_id, name)
    url = await asyncio.to_thread(_upload_and_get_url, local_path, object_key)
    await asyncio.to_thread(
        record_step,
        session_id=session_id,
        node="viz",
        step_type="plot",
        type="image",
        content=url,
    )
    return object_key

async def emit_file_from_path(session_id: str, local_path: str, *, prefix: str = "processfiles") -> str:
    """
    ä¸Šä¼ ä»»æ„æ–‡ä»¶å¹¶æ¨é€äº‹ä»¶ï¼ˆå‰ç«¯æ˜¾ç¤ºä¸‹è½½é“¾æ¥ï¼‰ï¼š
    - äº‹ä»¶ï¼štype="file"ï¼Œcontent=<url>ï¼Œresult={"filename": "...", "object_key": "..."}
    """
    name = Path(local_path).name
    object_key = _mk_key(prefix, session_id, name)
    url = await asyncio.to_thread(_upload_and_get_url, local_path, object_key)
    await asyncio.to_thread(
        record_step,
        session_id=session_id,
        node="artifact",
        step_type="file",
        type="file",
        content=url,
        result={"filename": name, "object_key": object_key},
    )
    return object_key

async def emit_bytes_as_file(session_id: str, data: bytes, filename: str, *, prefix: str = "processfiles") -> str:
    """
    æŠŠå†…å­˜å­—èŠ‚ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ â†’ ä¸Šä¼  â†’ æ¨é€ file äº‹ä»¶ã€‚
    """
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(data)
        tmp.flush()
        tmp_path = tmp.name
    try:
        return await emit_file_from_path(session_id, tmp_path, prefix=prefix)
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass

# ============ è§„åˆ’ + ç”Ÿæˆæµç¨‹å›¾ï¼ˆä¸Šä¼ åˆ° pic/flowchart/...ï¼‰ ============
async def _plan_and_graph(user_input: str, session_id: str) -> Tuple[Any, List[Dict[str, Any]], Optional[str]]:
    """
    è§„åˆ’ä»»åŠ¡ + ç”Ÿæˆå¹¶ä¸Šä¼ æµç¨‹å›¾
    è¿”å›: (compiled_graph, tasks, graph_url)
    """
    # 1) ä»»åŠ¡è§„åˆ’
    cases = load_case_templates()
    tasks, ai_msg = await llm_pick_tasks(user_input, cases)

    # æ¨é€ planner æ€è€ƒï¼ˆthought æ”¾è¯¦ç»†æ¨ç†ï¼›content å¯æ”¾ç®€çŸ­ç»“è®º/ç¼–å·ï¼‰
    if ai_msg:
        thought, answer = split_thought_and_answer(ai_msg.content)
        await asyncio.to_thread(
            record_step,
            session_id=session_id,
            node="planner",
            step_type="llm",
            type="thought",
            thought=thought,
            content=answer,  # å¯èƒ½æ˜¯ "2" æˆ–ä¸€ä¸ªç®€çŸ­ç»“è®º
            model=(ai_msg.response_metadata or {}).get("model") if hasattr(ai_msg, "response_metadata") else None,
            usage=getattr(ai_msg, "usage_metadata", None),
        )
    else:
        logger.warning("planner æ—  AIMessageï¼Œè·³è¿‡è®°å½•æ€è€ƒ")

    logger.info("LLM è§„åˆ’ä»»åŠ¡æµ: %s", tasks)

    # 2) æ„å›¾
    compiled = build_graph(tasks)

    # 3) æµç¨‹å›¾ â†’ æœ¬åœ° â†’ MinIOï¼ˆflowchart/...ï¼‰â†’ æ¨ image äº‹ä»¶
    graph_url: Optional[str] = None
    try:
        core = sid_core(session_id)                       # â† ç»Ÿä¸€ç”¨æ ¸å¿ƒID
        ts = int(time.time())                             # â† å¯é€‰ï¼šæ—¶é—´æˆ³é¿å…è¦†ç›–
        graph_path = _GRAPHS_DIR / f"graph_{core}_{ts}.png"      # â† æœ¬åœ°æ–‡ä»¶åä¹Ÿç»Ÿä¸€

        png_bytes = compiled.get_graph(xray=True).draw_mermaid_png()
        graph_path.write_bytes(png_bytes)

        # ä¸å†èµ° _mk_key("pic/flowchart", ...)ï¼Œç›´æ¥æ˜ç¡®ï¼šflowchart/<core>/graph_<core>_<ts>.png
        object_key = f"flowchart/{core}/graph_{core}_{ts}.png"    # â† ç›®æ ‡å¯¹è±¡é”®ç»Ÿä¸€

        graph_url = await asyncio.to_thread(_upload_and_get_url, str(graph_path), object_key)

        await asyncio.to_thread(
            record_step,
            session_id=session_id,
            node="planner",
            step_type="flowchart",
            type="image",
            content=graph_url,
        )
    except Exception as e:
        logger.warning("æµç¨‹å›¾ç”Ÿæˆæˆ–ä¸Šä¼ å¤±è´¥ï¼š%s", e)


    # 4) æ¨ planner é˜¶æ®µçš„ä»»åŠ¡åˆ—è¡¨ï¼ˆç»“æ„åŒ–ï¼‰
    await asyncio.to_thread(
        record_step,
        session_id=session_id,
        node="planner",
        step_type="result",
        type="trace",
        result={"tasks": tasks},
    )

    return compiled, tasks, graph_url

# ================== ä¸»æµç¨‹ï¼ˆæµå¼ï¼‰ ==================
async def run_dynamic_pipeline_streaming(
    txt_path: str | Path,
    user_input: str,
    session_id: Optional[str] = None,
) -> Dict[str, Any]:
    """
    æµå¼ç‰ˆæœ¬ï¼šè®°å½•è§„åˆ’æ€è€ƒã€ä¸Šä¼ æµç¨‹å›¾åˆ° pic/...ã€æ‰§è¡Œå„èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹å†…å¯ç”¨ emit_* å‘å›¾/æ–‡ä»¶ï¼‰
    è¿”å›ï¼šç®€è¦ç»“æœå­—å…¸ï¼ˆä¾› api_core æ¨ result äº‹ä»¶ï¼‰
    """
    session_id = session_id or "default"
    logger.info("ğŸŸ¢ [Streaming] è°ƒç”¨ pipeline, file=%s, query=%s", txt_path, user_input)

    # å¼€å§‹äº‹ä»¶
    await asyncio.to_thread(
        record_step,
        session_id=session_id,
        node="pipeline",
        step_type="start",
        type="start",
        content=f"å¼€å§‹å¤„ç†ï¼š{txt_path}",
    )

    try:
        # 1) è§„åˆ’ + æµç¨‹å›¾
        compiled, tasks, graph_url = await _plan_and_graph(user_input, session_id)

        # 2) æ‰§è¡Œå›¾ï¼›å°†æ¯æ­¥è¾“å‡ºå®æ—¶å†™å…¥ traceï¼ˆåˆ†ç±»ä¸º call/resultï¼‰ï¼Œå‰ç«¯å³å¯æµå¼æ˜¾ç¤º
        async for output in compiled.astream({
            "path": Path(txt_path),
            "user_input": user_input,
            "session_id": session_id,
        }):
            output = safe_serialize(output)

            # âœ… å®æ—¶æ¨æµåˆ° traceï¼šå°½é‡è¯†åˆ« å·¥å…·è°ƒç”¨/ç»“æœï¼›è¿‡æ»¤ /tmp å™ªå£°
            try:
                step_type = None
                tool_name = None
                payload   = None

                if isinstance(output, dict):
                    ev = str(output.get("event") or "")
                    # å½¢å¦‚ {event: 'tool_call', tool_name: 'xxx', args: {...}}
                    if ev in ("tool_call", "call"):
                        step_type = "call"
                        tool_name = output.get("tool") or output.get("tool_name")
                        payload   = output.get("args") or {k: v for k, v in output.items() if k not in ("event",)}
                    # å½¢å¦‚ {event: 'tool_result', tool_name: 'xxx', result: {...}}
                    elif ev in ("tool_result", "result") or ("result" in output):
                        step_type = "result"
                        tool_name = output.get("tool") or output.get("tool_name")
                        payload   = output.get("result") or {k: v for k, v in output.items() if k not in ("event",)}
                    # å·²ç»æ˜¯å›¾ç‰‡äº‹ä»¶ï¼ˆæŸäº›èŠ‚ç‚¹ä¹Ÿå¯èƒ½ä¸»åŠ¨äº§å‡ºï¼‰ï¼Œç›´æ¥è½¬å‘
                    elif (output.get("type") == "image") and output.get("content"):
                        record_step(
                            session_id=session_id,
                            node=output.get("node") or "graph",
                            step_type=output.get("step_type") or "plot",
                            type="image",
                            content=str(output.get("content")),
                        )
                        payload = None  # å·²å¤„ç†
                    else:
                        step_type = "result"
                        payload   = output
                else:
                    # é dictï¼šä¹ŸæŒ‰ result æ–‡æœ¬æ¨ä¸€æ¬¡
                    step_type = "result"
                    payload   = output

                # è¿‡æ»¤æ‰ {"path": "/tmp/tmpxxxx"} è¿™ç§å™ªå£°
                if isinstance(payload, dict) and set(payload.keys()) == {"path"} and str(payload.get("path", "")).startswith("/tmp/tmp"):
                    pass
                elif payload is not None:
                    record_step(
                        session_id=session_id,
                        node="graph",
                        step_type=step_type,
                        type="trace",
                        tool_name=tool_name,
                        result=payload if isinstance(payload, dict) else None,
                        content=None if isinstance(payload, dict) else str(payload),
                    )
            except Exception as _e:
                # ä¸è¦å½±å“ä¸»æµç¨‹
                logger.debug("stream push ignore error: %s", _e)

            # ï¼ˆå¯é€‰ï¼‰ä»ç„¶å†™å…¥æœ¬åœ° jsonl å¤‡æŸ¥
            log_path = _LOG_DIR / f"pipeline_{session_id}.jsonl"
            with open(log_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(output, ensure_ascii=False) + "\n")

    except Exception as e:
        logger.error("âŒ Pipeline æ‰§è¡Œå¼‚å¸¸: %s", e)
        await asyncio.to_thread(
            record_step,
            session_id=session_id,
            node="pipeline",
            step_type="exception",
            type="error",
            content=str(e),
        )
        return {
            "status": "error",
            "session_id": session_id,
            "message": str(e),
        }

    # ç»“æŸäº‹ä»¶
    await asyncio.to_thread(
        record_step,
        session_id=session_id,
        node="pipeline",
        step_type="end",
        type="end",
        content="ä»»åŠ¡å®Œæˆ",
    )

    return {
        "status": "ok",
        "session_id": session_id,
        "graph_url": graph_url,
    }

# ---------- ä¾› api_core è‡ªåŠ¨è§£æçš„å…¥å£å‡½æ•° ----------
async def run(file_path: str, query: str, session_id: str) -> Dict[str, Any]:
    return await run_dynamic_pipeline_streaming(
        txt_path=file_path,
        user_input=query,
        session_id=session_id,
    )

async def run_pipeline(file_path: str, query: str, session_id: str) -> Dict[str, Any]:
    return await run(file_path=file_path, query=query, session_id=session_id)

async def analyze(file_path: str, query: str, session_id: str) -> Dict[str, Any]:
    return await run(file_path=file_path, query=query, session_id=session_id)
