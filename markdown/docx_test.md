![](media/image1.png){width="5.773611111111111in"
height="4.269444444444445in"}

å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰åœ¨è‡ªä¸»æ‰§è¡Œå¤æ‚ä»»åŠ¡æ–¹é¢å±•çŽ°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¾‹å¦‚ç½‘é¡µå¯¼èˆªã€è®¾å¤‡æŽ§åˆ¶ã€ä»£ç ç¼–å†™å’Œç»´æŠ¤ç­‰ã€‚ç„¶è€Œï¼Œè¦åœ¨æ¶‰åŠå¤šè½®å†³ç­–çš„ä»»åŠ¡ä¸­å®žçŽ°æœ€ä½³æ€§èƒ½ï¼Œæ™ºèƒ½ä½“éœ€è¦ç›´æŽ¥ä¼˜åŒ–å¤šè½®ç›®æ ‡ï¼Œå¦‚æˆåŠŸçŽ‡ï¼Œè¿™æ¯”ä»…ä»…æ¨¡ä»¿æ¯ä¸ªå›žåˆä¸­æœ€å¯èƒ½çš„åŠ¨ä½œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

çŽ°æœ‰çš„å•è½®å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚RLHFï¼‰åœ¨å¤šè½®ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œä¸»è¦åŽŸå› åœ¨äºŽå®ƒä»¬æ— æ³•åœ¨å¤šä¸ªå›žåˆä¹‹é—´è¿›è¡Œæœ‰æ•ˆçš„ä¿¡ç”¨åˆ†é…ã€‚æ­¤å¤–ï¼Œå°½ç®¡ä¸€äº›ç ”ç©¶å°è¯•åº”ç”¨å€¼å‡½æ•°å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚TD-learningï¼‰ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æœ‰é™çš„å¾®è°ƒæ•°æ®ä¸‹æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚å› æ­¤ï¼Œå¦‚ä½•å¼€å‘ä¸€ç§èƒ½å¤Ÿå……åˆ†åˆ©ç”¨LLMæŽ¨ç†èƒ½åŠ›çš„å¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£ä¹‹è°œã€‚

**2. ç›¸å…³å·¥ä½œ**

**2.1 LLMæ™ºèƒ½ä½“çš„åŸºå‡†æµ‹è¯•**

è¿‘å¹´æ¥ï¼Œè®¸å¤šåŸºå‡†æµ‹è¯•è¢«æå‡ºç”¨äºŽè¯„ä¼°LLMæ™ºèƒ½ä½“åœ¨ä¸åŒåœºæ™¯ä¸‹çš„èƒ½åŠ›ï¼Œå¦‚è½¯ä»¶å·¥ç¨‹ã€ç½‘é¡µå¯¼èˆªã€è®¾å¤‡æŽ§åˆ¶å’Œæ—…è¡Œè§„åˆ’ç­‰ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨è¯„ä¼°æœ€å…ˆè¿›çš„é€šç”¨LLMï¼Œè€Œç¼ºä¹ä¸€ä¸ªç ”ç©¶å‹å¥½çš„äº¤äº’çŽ¯å¢ƒå’Œè®­ç»ƒä»»åŠ¡é›†æ¥ç ”ç©¶å¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚ColBenchæ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ä¸ºå¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•è®¾è®¡çš„åŸºå‡†æµ‹è¯•ï¼Œä¸“æ³¨äºŽå…·æœ‰å¼ºæŽ¨ç†èƒ½åŠ›çš„ä»»åŠ¡ï¼Œå¹¶æä¾›äº†å¯é çš„åŠŸèƒ½éªŒè¯å™¨ã€‚

**2.2 å¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•**

ä¸Žå•è½®åœºæ™¯ä¸åŒï¼Œå¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•éœ€è¦æ™ºèƒ½ä½“åœ¨å®Œæˆä»»åŠ¡æ—¶è¿›è¡Œä¸€ç³»åˆ—åŠ¨ä½œã€‚å°½ç®¡ä¸€äº›æ—©æœŸç ”ç©¶ç›´æŽ¥åº”ç”¨äº†å•è½®å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚REINFORCEã€[DPO]{.underline}å’ŒPPOï¼‰ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ä»»åŠ¡æ—¶é—´è·¨åº¦è¾ƒé•¿æ—¶å¾€å¾€è¡¨çŽ°ä¸ä½³ã€‚æœ€è¿‘çš„ç ”ç©¶å°è¯•åº”ç”¨æ›´å…ˆè¿›çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼ˆå¦‚Bellman
bootstrappingå’ŒPath
Consistencyï¼‰æ¥å‡å°‘é•¿æœŸæ–¹å·®ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å¤šè½®ä»»åŠ¡ä¸­çš„è¡¨çŽ°ä»ç„¶æœ‰é™ã€‚

**3. åä½œæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ï¼ˆColBenchï¼‰**

**3.1 è®¾è®¡åŽŸåˆ™**

ColBenchçš„è®¾è®¡éµå¾ªä¸‰ä¸ªæ ¸å¿ƒåŽŸåˆ™ï¼š

1.  **ä»»åŠ¡å¤æ‚æ€§**ï¼šåŸºå‡†æµ‹è¯•åº”åæ˜ çŽ°å®žä¸–ç•Œä¸­çš„å¤æ‚æŽ¨ç†å’Œæ³›åŒ–æŒ‘æˆ˜ã€‚

2.  **æœ€å°å·¥ç¨‹å¼€é”€**ï¼šä¸ºäº†å¿«é€Ÿç ”ç©¶åŽŸåž‹è®¾è®¡ï¼ŒåŸºå‡†æµ‹è¯•åº”å°½é‡å‡å°‘å·¥ç¨‹å¼€é”€ã€‚

3.  **ä»»åŠ¡å¤šæ ·æ€§**ï¼šåŸºå‡†æµ‹è¯•åº”åŒ…å«è¶³å¤Ÿçš„ä»»åŠ¡ï¼Œä»¥ç¡®ä¿ä¸åŒå¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å¯æ‰©å±•æ€§ã€‚

**3.2 åŽç«¯ç¼–ç¨‹åä½œ**

åœ¨**åŽç«¯ç¼–ç¨‹åä½œ**ä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦ä¸Žäººç±»æ¨¡æ‹Ÿå™¨åä½œç¼–å†™ä¸€ä¸ªè‡ªå®šä¹‰çš„Pythonå‡½æ•°ã€‚ä»»åŠ¡å¼€å§‹æ—¶ï¼Œæ™ºèƒ½ä½“èŽ·å¾—å‡½æ•°çš„é«˜çº§æè¿°å’Œç­¾åï¼Œä½†è®¸å¤šå…·ä½“ç»†èŠ‚ï¼ˆå¦‚æ¡ä»¶å’Œè¾¹ç¼˜æƒ…å†µï¼‰å¹¶æœªæä¾›ï¼Œæ™ºèƒ½ä½“éœ€è¦é€šè¿‡æé—®æ¥èŽ·å–æ›´å¤šä¿¡æ¯ã€‚äººç±»æ¨¡æ‹Ÿå™¨ä¼šæ ¹æ®å‚è€ƒä»£ç æä¾›ç®€è¦çš„è‡ªç„¶è¯­è¨€è§£é‡Šï¼Œä½†ä¸ä¼šç›´æŽ¥ç¼–å†™ä»£ç ã€‚äº¤äº’æœ€å¤šè¿›è¡Œ10è½®ï¼Œæœ€ç»ˆé€šè¿‡10ä¸ªéšè—çš„å•å…ƒæµ‹è¯•æ¥è¯„ä¼°æ™ºèƒ½ä½“çš„æˆåŠŸä¸Žå¦ã€‚

**3.3 å‰ç«¯è®¾è®¡åä½œ**

åœ¨**å‰ç«¯è®¾è®¡åä½œ**ä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦ä¸Žäººç±»æ¨¡æ‹Ÿå™¨åä½œè®¾è®¡ä¸€ä¸ªç½‘é¡µã€‚ä»»åŠ¡å¼€å§‹æ—¶ï¼Œæ™ºèƒ½ä½“èŽ·å¾—ç½‘é¡µçš„é«˜çº§æè¿°ï¼Œä½†è®¸å¤šå…·ä½“ç»†èŠ‚ï¼ˆå¦‚å¸ƒå±€å’Œé¢œè‰²æ–¹æ¡ˆï¼‰å¹¶æœªæä¾›ã€‚æ™ºèƒ½ä½“åœ¨æ¯ä¸ªå›žåˆä¸­ç¼–å†™HTMLä»£ç ï¼Œå¹¶é€šè¿‡æµè§ˆå™¨æ¸²æŸ“ç½‘é¡µã€‚äººç±»æ¨¡æ‹Ÿå™¨ä¼šæ£€æŸ¥æ¸²æŸ“çš„ç½‘é¡µä¸Žå‚è€ƒç½‘é¡µçš„å·®å¼‚ï¼Œå¹¶å‘æ™ºèƒ½ä½“æè¿°è¿™äº›å·®å¼‚ã€‚æœ€ç»ˆé€šè¿‡CLIPåµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¯„ä¼°æ™ºèƒ½ä½“çš„è¡¨çŽ°ã€‚

**4.1 é—®é¢˜è®¾ç½®**

åœ¨å¤šè½®åä½œä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦ä¸Žäººç±»æ¨¡æ‹Ÿå™¨è¿›è¡Œå¤šæ¬¡äº¤äº’ï¼Œé€æ­¥å®Œæˆä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿå°†è¿™ä¸€é—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ª**æœ‰é™æ—¶åŸŸçš„éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPï¼‰**ï¼Œè®°ä¸º
M={O,C,A,T,*Î¼*1â€‹,R,*N*}ã€‚å…¶ä¸­ï¼š

-   O è¡¨ç¤ºæ™ºèƒ½ä½“å¯ä»¥è§‚å¯Ÿåˆ°çš„çŠ¶æ€ç©ºé—´éƒ¨åˆ†ã€‚

-   C è¡¨ç¤ºéšè—çš„çŠ¶æ€ç©ºé—´éƒ¨åˆ†ï¼Œé€šå¸¸åŒ…æ‹¬ä»»åŠ¡çš„å…³é”®ä¿¡æ¯ï¼ˆå¦‚å‚è€ƒè§£å†³æ–¹æ¡ˆï¼‰ã€‚

-   A è¡¨ç¤ºæ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´ï¼Œå³æ™ºèƒ½ä½“åœ¨æ¯ä¸ªå›žåˆä¸­ç”Ÿæˆçš„å“åº”ã€‚

-   T è¡¨ç¤ºçŠ¶æ€è½¬ç§»å‡½æ•°ï¼Œæ™ºèƒ½ä½“åœ¨é‡‡å–åŠ¨ä½œåŽï¼ŒçŽ¯å¢ƒä¼šæ ¹æ®è½¬ç§»å‡½æ•°æ›´æ–°çŠ¶æ€ã€‚

-   *Î¼*1â€‹
    æ˜¯åˆå§‹çŠ¶æ€åˆ†å¸ƒï¼Œæ™ºèƒ½ä½“åœ¨ä»»åŠ¡å¼€å§‹æ—¶ä»Žè¯¥åˆ†å¸ƒä¸­é‡‡æ ·åˆå§‹æŒ‡ä»¤å’Œéšè—ä¿¡æ¯ã€‚

-   R æ˜¯å¥–åŠ±å‡½æ•°ï¼Œæ™ºèƒ½ä½“åœ¨æ¯ä¸ªå›žåˆä¸­æ ¹æ®å…¶åŠ¨ä½œå’Œéšè—ä¿¡æ¯èŽ·å¾—å¥–åŠ±ã€‚

-   *N*Â æ˜¯ä»»åŠ¡çš„æœ€å¤§å›žåˆæ•°ã€‚

åœ¨æ¯ä¸ªå›žåˆ t*t*ï¼Œæ™ºèƒ½ä½“è§‚å¯Ÿåˆ°åŽ†å²äº¤äº’ä¿¡æ¯ ot*ot*â€‹ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåŠ¨ä½œ
at*at*â€‹ï¼ˆå³ä¸€ä¸ªç”±å¤šä¸ªä»¤ç‰Œç»„æˆçš„å“åº”ï¼‰ã€‚ç”¨æˆ·ä¼šæ ¹æ®æ™ºèƒ½ä½“çš„åŠ¨ä½œç»™å‡ºåé¦ˆï¼Œæ™ºèƒ½ä½“çš„çŠ¶æ€æ›´æ–°ä¸ºæ–°çš„äº¤äº’åŽ†å²ã€‚ä»»åŠ¡ç»“æŸæ—¶ï¼Œæ™ºèƒ½ä½“æ ¹æ®ç´¯ç§¯å¥–åŠ±è¿›è¡Œè¯„ä¼°ã€‚

**4.2 å­¦ä¹ å›žåˆçº§ä¼˜åŠ¿å‡½æ•°**

åœ¨å¤šè½®ä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦åœ¨æ¯ä¸ªå›žåˆä¸­åšå‡ºå†³ç­–ï¼Œè€Œè¿™äº›å†³ç­–çš„é•¿æœŸå½±å“å¾€å¾€éš¾ä»¥ç›´æŽ¥è¯„ä¼°ã€‚ä¸ºäº†æœ‰æ•ˆåˆ†é…ä¿¡ç”¨ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºç›´æŽ¥å­¦ä¹ æ¯ä¸ªå›žåˆåŠ¨ä½œçš„**ä¼˜åŠ¿å‡½æ•°**ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„å€¼å‡½æ•°ã€‚

ä¼˜åŠ¿å‡½æ•°Â *AÏ€*(*ot*â€‹,*at*â€‹,*c*) è¡¨ç¤ºåœ¨å½“å‰çŠ¶æ€(*ot*â€‹,*c*)
ä¸‹é‡‡å–åŠ¨ä½œÂ *at*â€‹
çš„ç›¸å¯¹æ”¶ç›Šã€‚ä¸Žå€¼å‡½æ•°ä¸åŒï¼Œä¼˜åŠ¿å‡½æ•°ç›´æŽ¥è¡¡é‡æ¯ä¸ªåŠ¨ä½œçš„æ•ˆç”¨ï¼Œè€Œä¸éœ€è¦å…ˆä¼°è®¡å½“å‰çŠ¶æ€çš„å€¼ã€‚

ç ”ç©¶å›¢é˜Ÿä½¿ç”¨**[Bradley-Terryç›®æ ‡å‡½æ•°]{.underline}**æ¥è®­ç»ƒä¼˜åŠ¿å‡½æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸¤ä¸ªè½¨è¿¹Â *Ï„*+
å’ŒÂ *Ï„*âˆ’ï¼Œå…¶ä¸­Â *Ï„*+ æ˜¯æˆåŠŸè½¨è¿¹ï¼Œ*Ï„*âˆ’
æ˜¯å¤±è´¥è½¨è¿¹ï¼Œä¼˜åŠ¿å‡½æ•°çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æˆåŠŸè½¨è¿¹ä¸­æ¯ä¸ªåŠ¨ä½œçš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æœ€å°åŒ–å¤±è´¥è½¨è¿¹ä¸­æ¯ä¸ªåŠ¨ä½œçš„ä¼˜åŠ¿ã€‚ä¼˜åŠ¿å‡½æ•°çš„å­¦ä¹ ç›®æ ‡å¯ä»¥è¡¨ç¤ºä¸ºï¼š

![](media/image2.png){width="5.7652777777777775in"
height="0.6173611111111111in"}

å…¶ä¸­ï¼Œ*Ïƒ*Â æ˜¯sigmoidå‡½æ•°ï¼Œ*Î²*Â æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºŽæŽ§åˆ¶ä¼˜åŠ¿å‡½æ•°çš„ç¼©æ”¾ã€‚

ä¸ºäº†ä¸ŽLLMçš„é¢„è®­ç»ƒç›®æ ‡ä¿æŒä¸€è‡´ï¼Œç ”ç©¶å›¢é˜Ÿå°†ä¼˜åŠ¿å‡½æ•°å‚æ•°åŒ–ä¸ºLLMçš„å‡å€¼å¯¹æ•°æ¦‚çŽ‡ï¼š

![](media/image3.png){width="5.7652777777777775in"
height="0.6784722222222223in"}

å…¶ä¸­ï¼Œ*Ï€Î¸*â€‹ æ˜¯è®­ç»ƒä¸­çš„LLMæ¨¡åž‹ï¼ŒÂ Â â€‹
æ˜¯ä¸€ä¸ªå†»ç»“çš„åˆå§‹æ¨¡åž‹ï¼Œ*L*Â æ˜¯å“åº”çš„é•¿åº¦ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä¼˜åŠ¿å‡½æ•°èƒ½å¤Ÿå……åˆ†åˆ©ç”¨LLMçš„æŽ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šè½®ä»»åŠ¡ä¸­è¿›è¡Œæœ‰æ•ˆçš„ä¿¡ç”¨åˆ†é…ã€‚

**4.3 é€šè¿‡å›žåˆçº§ä¼˜åŠ¿ä¼˜åŒ–æ™ºèƒ½ä½“**

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“çš„ç­–ç•¥Â *Ï€Ï•*â€‹
æ— æ³•ä¾èµ–äºŽéšè—ä¿¡æ¯Â *c*ï¼Œä½†è¿™äº›ä¿¡æ¯åœ¨è®­ç»ƒæ—¶æ˜¯å¯ç”¨çš„ã€‚å› æ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§**ä¸å¯¹ç§°çš„æ¼”å‘˜-è¯„è®ºå®¶ç»“æž„(**actor-critic
structure**)**ï¼Œå…¶ä¸­è¯„è®ºå®¶ï¼ˆä¼˜åŠ¿å‡½æ•°ï¼‰å¯ä»¥è®¿é—®éšè—ä¿¡æ¯ï¼Œè€Œæ¼”å‘˜ï¼ˆç­–ç•¥ï¼‰åªèƒ½è®¿é—®äº¤äº’åŽ†å²ã€‚

å…·ä½“æ¥è¯´ï¼Œè¯„è®ºå®¶é€šè¿‡è®­ç»ƒæ—¶ä¿¡æ¯ï¼ˆå¦‚å‚è€ƒè§£å†³æ–¹æ¡ˆï¼‰æ¥è¯„ä¼°æ¯ä¸ªåŠ¨ä½œçš„ä¼˜åŠ¿ï¼Œè€Œç­–ç•¥åˆ™æ ¹æ®äº¤äº’åŽ†å²ç”ŸæˆåŠ¨ä½œã€‚è¿™ç§ä¸å¯¹ç§°ç»“æž„ä½¿å¾—è¯„è®ºå®¶èƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°ç­–ç•¥çš„åŠ¨ä½œï¼Œä»Žè€Œå¸®åŠ©ç­–ç•¥åœ¨å¤šè½®ä»»åŠ¡ä¸­è¿›è¡Œä¼˜åŒ–ã€‚

ç ”ç©¶å›¢é˜Ÿä½¿ç”¨\*\*DPOï¼ˆDirect Preference
Optimizationï¼‰\*\*ç®—æ³•æ¥ä¼˜åŒ–ç­–ç•¥ã€‚åœ¨æ¯ä¸ªå›žåˆ
t*t*ï¼Œç­–ç•¥ç”Ÿæˆå¤šä¸ªå€™é€‰åŠ¨ä½œï¼Œå¹¶æ ¹æ®è¯„è®ºå®¶è¯„ä¼°çš„ä¼˜åŠ¿å€¼å¯¹è¿™äº›åŠ¨ä½œè¿›è¡ŒæŽ’åºã€‚ç„¶åŽï¼Œç­–ç•¥é€šè¿‡DPOæŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼š

![](media/image4.png){width="5.7652777777777775in" height="0.6in"}

å…¶ä¸­ï¼Œ*a*+ å’ŒÂ *a*âˆ’ åˆ†åˆ«æ˜¯æ ¹æ®ä¼˜åŠ¿å€¼æŽ’åºåŽçš„ä¼˜é€‰åŠ¨ä½œå’ŒåŠ£é€‰åŠ¨ä½œï¼Œ*Î²*â€²
æ˜¯ä¸€ä¸ªè¶…å‚æ•°ã€‚

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç­–ç•¥èƒ½å¤Ÿåœ¨æ¯ä¸ªå›žåˆä¸­ç”Ÿæˆæ›´ä¼˜çš„åŠ¨ä½œï¼Œä»Žè€Œåœ¨å¤šè½®ä»»åŠ¡ä¸­å–å¾—æ›´å¥½çš„è¡¨çŽ°ã€‚

**6. ç»“è®º**

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„å¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•SWEET-RLï¼Œå¹¶åœ¨ColBenchåŸºå‡†æµ‹è¯•ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSWEET-RLåœ¨å¤šè½®åä½œä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›ç®—æ³•ï¼Œä¸ºLLMæ™ºèƒ½ä½“çš„è®­ç»ƒæä¾›äº†æ–°çš„æ€è·¯ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æŽ¢ç´¢å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨è®­ç»ƒæ—¶ä¿¡æ¯ï¼Œä»¥å¼€å‘æ›´æœ‰æ•ˆçš„å¤šè½®å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚


---
### ðŸ–¼ OCR æå–æ–‡å­—

**å›¾ 1**

> SWEET-RL: Training Multi-Turn LLM Agents on
Collaborative Reasoning Tasks

Yifei Zhoul,21,ï¼Œ Song Jiang!, Yuandong Tian!, Jason Weston!, Sergey Levineâ€, Sainbayar Sukhbaatar!*,
Xian Li! *

1FAIR at Meta, 7UC Berkeley
tWork done at Meta, *Equal advising

Large language model (LLM) agents need to perform multi-turn interactions in real-world tasks.
However, existing multi-turn RL algorithms for optimizing LLM agents fail to perform effective credit
assignment over multiple turns while leveraging the generalization capabilities of LLMs and it remains
unclear how to develop such algorithms. To study this, we first introduce a new benchmark, ColBench,
where an LLM agent interacts with a human collaborator over multiple turns to solve realistic tasks
in backend programming and frontend design. Building on this benchmark, we propose a novel RL
algorithm, SWEET-RL (RL with Step-WisE Evaluation from Training-time information), that uses a
carefully designed optimization objective to train a critic model with access to additional training-time
information. The critic provides step-level rewards for improving the policy model. Our experiments
demonstrate that SWEET-RL achieves a 6% absolute improvement in success and win rates on
ColBench compared to other state-of-the-art multi-turn RL algorithms, enabling Llama-3.1-8B to
match or exceed the performance of GPT4-o in realistic collaborative content creation.

Date: March 20, 2025

Correspondence: Yifei Zhou at yifei_zhou@berkeley

Code: https://github.com/facebookresearch/sweet_rl

Data: https: //huggingface.co/datasets/facebook/collaborative_agent__bench                                 OO Meta

**å›¾ 2**

> Ja(O) = â€” log | (Zooetaa ä¸€ Zouweriaj :

(2)

**å›¾ 3**

> L
Aolor.ar,h) = +> |log T2Uetlee at 0)          3)
l=1

ol lou, a} on c)

**å›¾ 4**

> , log 74 (a*|oz)

 log m4 (a7 lor)

 

 

In) = logo (6

log Trep(at oz)

log Trep(a~|oz)

)

(4)
